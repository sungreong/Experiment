{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PreProcessingBASD_v2 import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd , sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import auc , roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append(\"/home/advice/Python/SR/Custom/\")\n",
    "from RAdam import RAdamOptimizer\n",
    "import seaborn as sns\n",
    "import re , os\n",
    "from ColumnMatch import MatchVariable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../../../Data/kdd/uci/uci_creditcard-train-0.2-0.0.csv\")\n",
    "in_var = [\"LIMIT_BAL\", \"SEX\", \"EDUCATION\", \"MARRIAGE\", \"AGE\", \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\",\n",
    "          \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\",\n",
    "          \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\"]\n",
    "target_var = ['default payment next month']\n",
    "fac_var = [ 'SEX','EDUCATION','MARRIAGE',]\n",
    "num_var = [i for i in in_var if not i in fac_var]\n",
    "#in_var = num_var + fac_var\n",
    "data[fac_var] = data[fac_var].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SEX', 'EDUCATION', 'MARRIAGE']"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col = data.select_dtypes(\"object\").columns.tolist()\n",
    "cat_col\n",
    "#onehot_data = pd.get_dummies(data , columns= cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_var = in_var + target_var + [\"sep_idx\"]\n",
    "data = data[select_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.sep_idx ==1 ]\n",
    "valid = data[data.sep_idx ==0 ]\n",
    "## \n",
    "train = data\n",
    "# _ = train.pop(\"sep_idx\")\n",
    "# _ = valid.pop(\"sep_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./../../../Data/kdd/uci/uci_creditcard-test-0.2-0.0.csv\")\n",
    "test[fac_var] = test[fac_var].astype(\"str\")\n",
    "# test = test.drop([\"ID\",\"sep_idx\"],axis=1)\n",
    "# test.reset_index(drop=True ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 25), (8982, 25), (6004, 26))"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform MissingData Method : mean\n",
      "Transform MissingData Method : most_frequent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('NumericImpute',\n",
       "                 MissingHandling(method=None,\n",
       "                                 trans_info={'fill_value': array([ 1.67484323e+05,  3.54752228e+01, -1.70900886e-02, -1.25958973e-01,\n",
       "       -1.65824567e-01, -2.16004663e-01, -2.64603095e-01, -2.86467414e-01,\n",
       "        5.10673010e+04,  4.95652237e+04,  4.70681142e+04,  4.32569520e+04,\n",
       "        4.04164970e+04,  3.88574464e+04,  5.69172658e+03,  5.81409563e+03...\n",
       "        5.13448505e+03,  4.83411333e+03,  4.76632123e+03,  5.24146976e+03]),\n",
       "                                            'norm_std': array([1.29747662e+05, 8.24146160e+00, 9.99950166e-01, 1.07116176e+00,\n",
       "       1.07345534e+00, 1.04935645e+00, 1.01015089e+00, 1.03371751e+00,\n",
       "       6.54338544e+04, 6.39443098e+04, 6.25215503e+04, 5.72229826e+04,\n",
       "       5.45746221e+04, 5.33084779e+04, 1.51993804e+04, 1.80845825e+04,\n",
       "       1.44245395e+04, 1.38536166e+04, 1.33906631e+04, 1.61330268e+04])}))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_info = {}\n",
    "Steps = [\n",
    "    (\"NumericImpute\", MissingHandling(method=\"mean\", \n",
    "                               trans_info= trans_info,\n",
    "                               var= num_var)) , \n",
    "    (\"FactorImpute\", MissingHandling(method=\"most_frequent\", \n",
    "                               trans_info= trans_info,\n",
    "                               var= fac_var)) , \n",
    "    (\"numeric\", NumericHandler(method=\"normal\",\n",
    "                               trans_info= trans_info,\n",
    "                               num_var=num_var)),\n",
    "]\n",
    "\n",
    "pipe = Pipeline(Steps)\n",
    "pipe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform MissingData Method : mean\n",
      "Transform MissingData Method : most_frequent\n",
      "Transform NumericData\n",
      "Transform MissingData Method : mean\n",
      "Transform MissingData Method : most_frequent\n",
      "Transform NumericData\n",
      "Transform MissingData Method : mean\n",
      "Transform MissingData Method : most_frequent\n",
      "Transform NumericData\n",
      "Transform MissingData Method : mean\n",
      "Transform MissingData Method : most_frequent\n",
      "Transform NumericData\n"
     ]
    }
   ],
   "source": [
    "pipe_op = BADSPipeLine(\"./0405_Piepeline.pkl\")\n",
    "pipe_op.save(pipe)\n",
    "pipe_op.load()\n",
    "pipe_op.transform(test)\n",
    "\n",
    "train = pipe_op.transform(train)\n",
    "valid = pipe_op.transform(valid)\n",
    "test = pipe_op.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX          object\n",
       "EDUCATION    object\n",
       "MARRIAGE     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[fac_var].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = train\n",
    "# category_info  = {}\n",
    "# for feat in fac_var:\n",
    "#     findIDX = [idx for idx, i in enumerate(in_var) if i == feat][0]\n",
    "#     lbe = LabelEncoder()\n",
    "#     lbe.fit(data[feat].values)\n",
    "#     diz_map_train = dict(zip(lbe.classes_, lbe.transform(lbe.classes_) + 1))\n",
    "#     print(f\"{feat} : {diz_map_train}\")\n",
    "#     category_info[feat] = diz_map_train\n",
    "# #     print(category_info)\n",
    "# # train.replace(category_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    14602\n",
       "1.0     9506\n",
       "nan     5892\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.replace(category_info)[fac_var[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feat in fac_var:\n",
    "#     current_key = list(category_info[feat].keys())\n",
    "#     remain_set = set(valid[feat]).difference(current_key)\n",
    "#     if remain_set == set() :\n",
    "#         pass\n",
    "#     else :\n",
    "#         for i in remain_set :  ## if not in train impose 0\n",
    "#             category_info[feat].update({i : 0})\n",
    "# valid2 = valid.replace(category_info)\n",
    "# for key, value in category_info.items() :\n",
    "#     valid2[key] = pd.Categorical(valid2[key],list(value.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid2[fac_var[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3}, 'EDUCATION': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, '4.0': 5, '5.0': 6, '6.0': 7, 'nan': 8}, 'MARRIAGE': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, 'nan': 5}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "category_info = {}\n",
    "\n",
    "class CategroyLabelEncoding(object) :\n",
    "    def __init__(self , fac_var , in_var) :\n",
    "        self.fac_var = fac_var\n",
    "        self.in_var = in_var\n",
    "        self.category_info = {}\n",
    "    \n",
    "    def fit(self, data) :\n",
    "        for feat in self.fac_var:\n",
    "            findIDX = [idx for idx, i in enumerate(self.in_var) if i == feat][0]\n",
    "            lbe = LabelEncoder()\n",
    "            lbe.fit(data[feat].values)\n",
    "            diz_map_train = dict(zip(lbe.classes_, lbe.transform(lbe.classes_) + 1))\n",
    "            self.category_info[feat] = diz_map_train\n",
    "        return \"label encoding\"\n",
    "    \n",
    "    def transform(self,data) :\n",
    "        for feat in self.fac_var:\n",
    "            findIDX = [idx for idx, i in enumerate(self.in_var) if i == feat][0]\n",
    "            current_key = list(self.category_info[feat].keys())\n",
    "            remain_set = set(data[feat]).difference(current_key)\n",
    "            if remain_set == set() :\n",
    "                pass\n",
    "            else :\n",
    "                for i in remain_set :  ## if not in train impose 0\n",
    "                    self.category_info[feat].update({i : 0})\n",
    "#         data[feat] = [diz_map_train[i] for i in data[feat].values]\n",
    "        print(self.category_info)\n",
    "        data2 = data.replace(self.category_info)\n",
    "        for key, value in  self.category_info.items() :\n",
    "            data2[key] = pd.Categorical(data2[key],list(value.values()))\n",
    "        return data2\n",
    "\n",
    "    \n",
    "testclass = CategroyLabelEncoding(fac_var , in_var)\n",
    "testclass.fit(train)\n",
    "train = testclass.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3}, 'EDUCATION': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, '4.0': 5, '5.0': 6, '6.0': 7, 'nan': 8}, 'MARRIAGE': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, 'nan': 5}}\n",
      "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3}, 'EDUCATION': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, '4.0': 5, '5.0': 6, '6.0': 7, 'nan': 8}, 'MARRIAGE': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, 'nan': 5}}\n"
     ]
    }
   ],
   "source": [
    "valid = testclass.transform(valid)\n",
    "test = testclass.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_info = testclass.category_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3},\n",
       " 'EDUCATION': {'0.0': 1,\n",
       "  '1.0': 2,\n",
       "  '2.0': 3,\n",
       "  '3.0': 4,\n",
       "  '4.0': 5,\n",
       "  '5.0': 6,\n",
       "  '6.0': 7,\n",
       "  'nan': 8},\n",
       " 'MARRIAGE': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, 'nan': 5}}"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X_np = train[in_var].values\n",
    "Train_y = train[target_var[0]]\n",
    "Test_X_np = test[in_var].values\n",
    "Test_y = test[target_var[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n"
     ]
    }
   ],
   "source": [
    "print(in_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[in_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'1.0': 1, '2.0': 2, 'nan': 3},\n",
       " 2: {'0.0': 1,\n",
       "  '1.0': 2,\n",
       "  '2.0': 3,\n",
       "  '3.0': 4,\n",
       "  '4.0': 5,\n",
       "  '5.0': 6,\n",
       "  '6.0': 7,\n",
       "  'nan': 8},\n",
       " 3: {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, 'nan': 5}}"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx , name in enumerate(in_var) :\n",
    "    if name in list(cat_info.keys()) :\n",
    "        cat_info[idx] = cat_info.pop(name)\n",
    "cat_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5280152"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(pd.get_dummies(train, columns= fac_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4890840"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.values[:,fac_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd , sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 23\n"
     ]
    }
   ],
   "source": [
    "row , dim = Train_X_np.shape\n",
    "print(row,dim)\n",
    "target_n = 2 \n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape = [ None , dim])\n",
    "y = tf.placeholder(tf.float32, shape = [ None , 1])\n",
    "DropoutRate = tf.placeholder(tf.float32, name =\"dropoutRate\")\n",
    "training = tf.placeholder_with_default(False, shape=[], name=\"training\")\n",
    "global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "batch_prob  = tf.placeholder(tf.bool)\n",
    "batch_size = tf.placeholder(tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 1 \n",
    "# split = tf.slice(X, [0, i], [-1, 1])\n",
    "# split =tf.cast(split, dtype=tf.int32)\n",
    "# split = tf.reshape(split,(-1,))\n",
    "# size = max(list(cat_info[i].values())) + 1\n",
    "# emb = 4\n",
    "# tf.keras.layers.Embedding(size,emb)(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'1.0': 1, '2.0': 2, 'nan': 3},\n",
       " 2: {'0.0': 1,\n",
       "  '1.0': 2,\n",
       "  '2.0': 3,\n",
       "  '3.0': 4,\n",
       "  '4.0': 5,\n",
       "  '5.0': 6,\n",
       "  '6.0': 7,\n",
       "  'nan': 8},\n",
       " 3: {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, 'nan': 5}}"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [1, 1], [2, 1], [3, 1], [4, 19]]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = np.arange(len(in_var))\n",
    "fac_idx = list(cat_info.keys())\n",
    "split = list(set(np.array(fac_idx)) | set(np.array(fac_idx ) + 1))\n",
    "lists = np.split(total , split)\n",
    "index_store = []\n",
    "for idx , i in enumerate(lists) :\n",
    "    if len(i) == 1 :\n",
    "        index_store.append([i[0],1])\n",
    "    else :\n",
    "        index_store.append([i[0],len(i) ] ) \n",
    "index_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RepresentationLayer(X, index_store,category_info, type,emb_dim) :\n",
    "    inputs = []\n",
    "    embs = {}\n",
    "    for index in index_store :\n",
    "        split = tf.slice(X, [0, index[0]], [-1, index[1]])\n",
    "        if index[0] in list(category_info.keys()) :\n",
    "            split =tf.cast(split, dtype=tf.int32)\n",
    "            split = tf.reshape(split,(-1,))\n",
    "            size = max(list(category_info[index[0]].values())) + 1\n",
    "            if type == \"embedding\" :    \n",
    "                Cat = tf.keras.layers.Embedding(size,emb_dim)(split)\n",
    "                embs[index[0]] = Cat\n",
    "            elif type == \"onehot\" :\n",
    "                Cat = tf.one_hot(split ,depth=size)\n",
    "            else :\n",
    "                raise Exception(f\"No Valid Type : {type}, Please Change the type to onehot or embedding\")\n",
    "            inputs.append(Cat)\n",
    "        else :\n",
    "            inputs.append(split)\n",
    "#     group_key = list(category_info.keys())\n",
    "#     group_vec = []\n",
    "#     for g_k in group_key :\n",
    "#         new_group_key = group_key[:]\n",
    "#         new_group_key.remove(g_k)\n",
    "#         dots = [tf.keras.layers.Dot(axes=1)([embs[k], embs[g_k]]) for k in new_group_key]\n",
    "#         dot_product = tf.keras.layers.Average()(dots)\n",
    "#         group_vec.append(dot_product)\n",
    "#     group_matrix = tf.concat(group_vec, axis=1, name='groupvec_')\n",
    "# #     group_matrix  = tf.nn.dropout(group_matrix, 0.5)\n",
    "#     group_matrix = tf.layers.batch_normalization(group_matrix,\n",
    "#                                                  center=True, scale=True, training=True)\n",
    "#     inputs.append(group_matrix )\n",
    "    concatenated_layer = tf.concat(inputs, axis=1, name='concatenate')\n",
    "    return concatenated_layer\n",
    "def Layer(X , reuse = False) :\n",
    "    with tf.variable_scope(\"Final\",reuse=reuse):\n",
    "        W_1 = tf.get_variable(\"w_1\",shape=[X.get_shape()[1],30])\n",
    "        B_1 = tf.get_variable(\"b_1\",shape=[30])\n",
    "        W_2 = tf.get_variable(\"w_2\",shape=[30,20])\n",
    "        B_2 = tf.get_variable(\"b_2\",shape=[20])\n",
    "        W_3 = tf.get_variable(\"w_3\",shape=[20,5])\n",
    "        B_3 = tf.get_variable(\"b_3\",shape=[5])\n",
    "        finalW = tf.get_variable(\"final_w\",shape=[5,1])\n",
    "        finalB = tf.get_variable(\"final_b\",shape=[1])\n",
    "        layer1 = tf.matmul(X, W_1) + B_1\n",
    "        layer1 = tf.layers.batch_normalization(layer1, \n",
    "                                               center=True, scale=True, training=batch_prob)\n",
    "        layer1 = tf.nn.selu(layer1)\n",
    "        layer1 = tf.nn.dropout(layer1, keep_prob=DropoutRate)\n",
    "        layer2 = tf.matmul(layer1, W_2) + B_2\n",
    "        layer2 = tf.layers.batch_normalization(layer2, \n",
    "                                               center=True, scale=True, training=batch_prob)\n",
    "        layer2 = tf.nn.selu(layer2)\n",
    "        layer2 = tf.nn.dropout(layer2, keep_prob=DropoutRate)\n",
    "        layer3 = tf.matmul(layer2, W_3) + B_3\n",
    "        layer3 = tf.layers.batch_normalization(layer3, \n",
    "                                               center=True, scale=True, training=batch_prob)\n",
    "        layer3 = tf.nn.selu(layer3)\n",
    "        layer3 = tf.nn.dropout(layer3, keep_prob=DropoutRate)\n",
    "        logit = tf.matmul(layer3, finalW) + finalB\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuple = (X,y)\n",
    "class_dataset = tf.data.Dataset.from_tensor_slices(data_tuple)\n",
    "class_dataset = class_dataset.shuffle(buffer_size= 30000,)\n",
    "class_dataset = class_dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "iter = class_dataset.make_initializable_iterator()\n",
    "feature_x , label_y = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureX = RepresentationLayer(feature_x , index_store , cat_info,\"onehot\",4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = Layer(FeatureX)\n",
    "prob= tf.nn.sigmoid(logit)\n",
    "auc_value , update_auc = tf.metrics.auc(label_y , prob , curve=\"ROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"Final\") \n",
    "totalvars = tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = tf.train.cosine_decay_restarts(1e-4, global_step,\n",
    "                                               first_decay_steps=100, t_mul=1.5,m_mul=0.9, alpha=0.0)\n",
    "loss2 = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(labels = label_y ,\n",
    "                                                                logits=logit,pos_weight=1.5))\n",
    "L2= []\n",
    "for v in totalvars :\n",
    "    L2.append(tf.nn.l2_loss(v))\n",
    "L2Regularizer= tf.add_n(L2)  * 0.01\n",
    "loss2 +=L2Regularizer\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    solver2 = tf.train.AdamOptimizer(learning_rate= learning_rate).minimize(loss2 ,var_list = totalvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.axes_grid1.inset_locator import (inset_axes, TransformedBbox,\n",
    "                                                   BboxPatch, BboxConnector)\n",
    "def my_mark_inset(parent_axes, inset_axes, loc1a=1, loc1b=1, loc2a=2, loc2b=2, **kwargs):\n",
    "    rect = TransformedBbox(inset_axes.viewLim, parent_axes.transData)\n",
    "    pp = BboxPatch(rect, fill=False, **kwargs)\n",
    "    parent_axes.add_patch(pp)\n",
    "    p1 = BboxConnector(inset_axes.bbox, rect, loc1=loc1a, loc2=loc1b, **kwargs)\n",
    "    inset_axes.add_patch(p1)\n",
    "    p1.set_clip_on(False)\n",
    "    p2 = BboxConnector(inset_axes.bbox, rect, loc1=loc2a, loc2=loc2b, **kwargs)\n",
    "    inset_axes.add_patch(p2)\n",
    "    p2.set_clip_on(False)\n",
    "    return pp, p1, p2\n",
    "def subplotting(ax , store , x , y ,cond={}, **kwargs) :\n",
    "    ax.plot(store[x],store[y],**kwargs)\n",
    "    if \"ylabel\" in cond :\n",
    "        ax.set_ylabel(cond[\"ylabel\"], fontsize= 10)\n",
    "    if \"xlabel\" in cond :\n",
    "        ax.set_xlabel(cond[\"xlabel\"], fontsize= 10)\n",
    "    if \"xlim\" in cond :\n",
    "        ax.set_xlim(cond[\"xlim\"])\n",
    "    if \"ylim\" in cond :\n",
    "        ax.set_ylim(cond[\"ylim\"])\n",
    "    if \"title\" in cond :\n",
    "        ax.set_title(cond[\"title\"], fontsize= 15)\n",
    "    ax.legend()\n",
    "    return ax\n",
    "## version3\n",
    "def vis_onlysl(store:dict, path:str,title:str) :\n",
    "    clear_output()\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = GridSpec(nrows=2, ncols=2)\n",
    "    ax1 = fig.add_subplot(gs[0:1, 0])\n",
    "    ax2 = fig.add_subplot(gs[0:1, 1])\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.99, \n",
    "            top=0.9, wspace=0.3, hspace=0.2)\n",
    "    ax1.plot(store[\"epoch\"],store[\"slloss\"],label = \"SLloss\", color='c')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    select_sl= np.argmin(store[\"slloss\"])\n",
    "    ax1.vlines(store[\"epoch\"][select_sl],\n",
    "               np.min(store[\"slloss\"]),np.max(store[\"slloss\"]),\n",
    "               label='Best', color='c')\n",
    "    a =store[\"slloss\"][-1]\n",
    "    ax1.set_title(f'Loss : {a:.4f}')\n",
    "    ax1.set_ylabel('Supervised', fontsize= 15)\n",
    "    ax1.legend()\n",
    "    ax2.plot(store[\"epoch\"],store[\"auc\"],label = \"Train auc\")\n",
    "    ax2.plot(store[\"epoch\"],store[\"teauc\"],label = \"Test auc\")\n",
    "    ax2.set_ylabel('AUC', fontsize= 15)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    select= np.argmax(store[\"teauc\"])\n",
    "    msg = f\"test idx : {store['epoch'][select]}, maximum : {store['teauc'][select]*100:.2f}\"\n",
    "    ax2.set_title(msg)             \n",
    "#     ax2.set_ylim(0.7,store['auc'][select]+0.1)\n",
    "    ax2.legend()\n",
    "    check_n = 4\n",
    "    if len(store['epoch']) > check_n :\n",
    "        axins = inset_axes(ax2, \"100%\", \"100%\", \n",
    "                           bbox_to_anchor=[0.36, .3, .5, .4],\n",
    "                       bbox_transform=ax2.transAxes, borderpad=0)\n",
    "        axins.plot(store['epoch'], store['auc'])\n",
    "        axins.plot(store['epoch'], store['teauc'])\n",
    "        maximum = np.max(store['auc'][-check_n:] + store['teauc'][-check_n:])\n",
    "        minumum = np.min(store['auc'][-check_n:] + store['teauc'][-check_n:])\n",
    "        xlims = (store['epoch'][-check_n],store['epoch'][-1])\n",
    "        ylims = (minumum, maximum)\n",
    "        axins.set(xlim=xlims, ylim=ylims)\n",
    "        my_mark_inset(ax2, axins, loc1a=2, loc1b=3, loc2a=4, loc2b=4, fc=\"none\", ec=\"0.5\") # \n",
    "#     msg = f\"Epoch : {epoch[-1]}, Loss : {loss[-1]:.3f}, Auc : {aucs[-1]:.3f}\"\n",
    "#     skplt.metrics.plot_ks_statistic(store[\"train_y\"], store[\"train_prob\"], \n",
    "#                                 ax = ax3 ,\n",
    "#                                 title = \"[Train] KS Static PLOT\")\n",
    "#     skplt.metrics.plot_ks_statistic(store[\"test_y\"], store[\"test_prob\"], \n",
    "#                                 ax = ax4 ,\n",
    "#                                 title = \"[Test] KS Static PLOT\")\n",
    "    sns.boxplot(x=\"t\", y=\"prob\", data=store[\"train_pd\"] , ax = ax3)\n",
    "    ax3.set_title(\"train\" , fontsize= 15)\n",
    "    sns.boxplot(x=\"t\", y=\"prob\", data=store[\"test_pd\"] , ax = ax4)\n",
    "    ax4.set_title(\"test\" , fontsize= 15)\n",
    "    plt.suptitle(title)\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from IPython.display import clear_output\n",
    "log = logging.getLogger('feature_x')\n",
    "log.setLevel(logging.DEBUG)\n",
    "log.propagate = True\n",
    "# os.path.join(os.getcwd(), LogPath)\n",
    "fileHandler = logging.FileHandler(f\"0405_CategoryHandler_log.txt\", mode=\"w\")\n",
    "streamHandler = logging.StreamHandler()\n",
    "fileHandler.setLevel(logging.DEBUG)\n",
    "streamHandler.setLevel(logging.CRITICAL)\n",
    "log.addHandler(fileHandler)\n",
    "log.addHandler(streamHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3985, SLLoss : 0.743\r"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "Epoch = 100000\n",
    "oversample = list(np.arange(len(Train_y))) + 2 * list(np.where(Train_y.values == 1)[0])\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import auc , roc_auc_score\n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init)\n",
    "    store = {\"epoch\" : [] ,  \"slloss\" : [],\n",
    "             \"auc\" : [], \"teauc\" : []}\n",
    "    store[\"train_pd\"] = []\n",
    "    store[\"test_pd\"] = []\n",
    "    for i in range(Epoch):    \n",
    "        batchSlLoss = []\n",
    "        permutation_idx = np.random.permutation(oversample)\n",
    "        sess.run(iter.initializer , \n",
    "                 feed_dict= {X : Train_X_np[permutation_idx],\n",
    "                             y : Train_y.values.reshape(-1,1)[[permutation_idx]],\n",
    "                             batch_size : 300,\n",
    "                            }) # switch to train dataset\n",
    "        while True :\n",
    "            try :\n",
    "                ### Supervised Learning\n",
    "                result  = sess.run([solver2 , loss2,FeatureX],\n",
    "                                   feed_dict={global_step:i, \n",
    "                                              batch_prob :True,\n",
    "                                              DropoutRate : 0.8\n",
    "                                             })\n",
    "                batchSlLoss.append(result[1])\n",
    "            except tf.errors.OutOfRangeError :\n",
    "                break\n",
    "        mslloss = np.mean(batchSlLoss)\n",
    "        print(f\"Epoch : {i}, SLLoss : {mslloss:.3f}\" , end = \"\\r\")\n",
    "        if (i % 100 == 0) :\n",
    "            log.info(str(i))\n",
    "            log.info(result[2][:3,:])\n",
    "            sess.run(iter.initializer , \n",
    "                     feed_dict= {X : Train_X_np,\n",
    "                     y : Train_y.values.reshape(-1,1),\n",
    "                     batch_size : len(Train_X_np),}) \n",
    "            tr_result  = sess.run([prob,label_y],\n",
    "                                  feed_dict={batch_prob :False,\n",
    "                                             DropoutRate : 1.0\n",
    "                                            })\n",
    "            sess.run(iter.initializer , \n",
    "                     feed_dict= {X : Test_X_np,\n",
    "                     y : Test_y.values.reshape(-1,1),\n",
    "                     batch_size : len(Test_X_np),}) \n",
    "            result  = sess.run([prob,label_y],\n",
    "                               feed_dict={batch_prob :False,\n",
    "                                          DropoutRate : 1.0\n",
    "                                         })\n",
    "            store[\"epoch\"].append(i)\n",
    "            store[\"slloss\"].append(mslloss)\n",
    "            store[\"train_pd\"] = pd.DataFrame(np.concatenate(tr_result,axis=1),\n",
    "                                             columns=[\"prob\",\"t\"])\n",
    "            store[\"test_pd\"] = pd.DataFrame(np.concatenate(result,axis=1),\n",
    "                                             columns=[\"prob\",\"t\"])\n",
    "            store[\"auc\"].append(roc_auc_score(store[\"train_pd\"][\"t\"].values,store[\"train_pd\"][\"prob\"].values))\n",
    "            store[\"teauc\"].append(roc_auc_score(store[\"test_pd\"][\"t\"].values,store[\"test_pd\"][\"prob\"].values))\n",
    "#             store[\"train_prob\"] =  np.concatenate((1-tr_result[2],tr_result[2]),axis=1)\n",
    "#             store[\"test_prob\"] =  np.concatenate((1-result[2],result[2]),axis=1)\n",
    "            vis_onlysl(store, \"./0405_SL_FeatureX.png\", title=\"Train SL\")\n",
    "            clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in  category_info.items() :\n",
    "    a[key] = pd.Categorical(a[key],list(value.values()))\n",
    "pd.get_dummies(a,columns=fac_var).columnsumns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX_1</th>\n",
       "      <th>SEX_2</th>\n",
       "      <th>SEX_3</th>\n",
       "      <th>EDUCATION_1</th>\n",
       "      <th>EDUCATION_2</th>\n",
       "      <th>EDUCATION_3</th>\n",
       "      <th>EDUCATION_4</th>\n",
       "      <th>EDUCATION_5</th>\n",
       "      <th>EDUCATION_6</th>\n",
       "      <th>EDUCATION_7</th>\n",
       "      <th>EDUCATION_8</th>\n",
       "      <th>MARRIAGE_1</th>\n",
       "      <th>MARRIAGE_2</th>\n",
       "      <th>MARRIAGE_3</th>\n",
       "      <th>MARRIAGE_4</th>\n",
       "      <th>MARRIAGE_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SEX_1, SEX_2, SEX_3, EDUCATION_1, EDUCATION_2, EDUCATION_3, EDUCATION_4, EDUCATION_5, EDUCATION_6, EDUCATION_7, EDUCATION_8, MARRIAGE_1, MARRIAGE_2, MARRIAGE_3, MARRIAGE_4, MARRIAGE_5]\n",
       "Index: []"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "      <th>sep_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20024.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29995</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22676.0</td>\n",
       "      <td>14647.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29996</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29997</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82607.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29998</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>8998.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29999</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>85900.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>52964.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX EDUCATION MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0        20000.0  2.0       2.0      1.0  24.0    2.0    2.0   -1.0   -1.0   \n",
       "1       120000.0  2.0       nan      2.0  26.0   -1.0    2.0    0.0    NaN   \n",
       "2        90000.0  2.0       2.0      2.0   NaN    0.0    0.0    0.0    0.0   \n",
       "3        50000.0  2.0       2.0      1.0  37.0    0.0    0.0    0.0    0.0   \n",
       "4        50000.0  1.0       nan      nan  37.0    0.0    0.0    0.0    0.0   \n",
       "...          ...  ...       ...      ...   ...    ...    ...    ...    ...   \n",
       "29995    50000.0  1.0       2.0      1.0  44.0    1.0    2.0    2.0    2.0   \n",
       "29996   240000.0  1.0       1.0      2.0  30.0   -2.0   -2.0   -2.0   -2.0   \n",
       "29997    80000.0  1.0       nan      nan  34.0    2.0    2.0    NaN    2.0   \n",
       "29998   150000.0  nan       3.0      2.0  43.0    NaN   -1.0    NaN   -1.0   \n",
       "29999    80000.0  1.0       3.0      nan  41.0    1.0   -1.0    NaN    NaN   \n",
       "\n",
       "       PAY_5  ...  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0       -2.0  ...        0.0        NaN       0.0     689.0       0.0   \n",
       "1        0.0  ...     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2        0.0  ...    14948.0    15549.0    1518.0    1500.0       NaN   \n",
       "3        0.0  ...    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4        0.0  ...        NaN    20024.0    2500.0    1815.0     657.0   \n",
       "...      ...  ...        ...        ...       ...       ...       ...   \n",
       "29995    0.0  ...    22676.0    14647.0    2300.0       NaN       0.0   \n",
       "29996   -2.0  ...        0.0        0.0       NaN       0.0       0.0   \n",
       "29997    2.0  ...    82607.0        NaN       NaN    3500.0       0.0   \n",
       "29998    NaN  ...     5190.0        0.0    1837.0    3526.0    8998.0   \n",
       "29999    0.0  ...        NaN    48944.0   85900.0    3409.0    1178.0   \n",
       "\n",
       "       PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  sep_idx  \n",
       "0           0.0       NaN       0.0                         1.0        1  \n",
       "1           NaN       0.0    2000.0                         1.0        1  \n",
       "2        1000.0    1000.0       NaN                         0.0        1  \n",
       "3        1100.0       NaN    1000.0                         0.0        1  \n",
       "4        1000.0       NaN     800.0                         0.0        1  \n",
       "...         ...       ...       ...                         ...      ...  \n",
       "29995     517.0     503.0     585.0                         0.0        0  \n",
       "29996       NaN       0.0       0.0                         0.0        0  \n",
       "29997    7000.0       0.0    4000.0                         1.0        0  \n",
       "29998     129.0       0.0       0.0                         0.0        0  \n",
       "29999    1926.0   52964.0    1804.0                         1.0        0  \n",
       "\n",
       "[30000 rows x 25 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.replace(category_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     for i in set(valid[feat]).difference(train[feat]):  ## if not in train impose 0\n",
    "#         diz_map_train[i] = 0\n",
    "\n",
    "#     for i in set(test[feat]).difference(train[feat]):  ## if not in train impose 0\n",
    "#         diz_map_train[i] = 0\n",
    "    \n",
    "#     train[feat] = [diz_map_train[i] for i in train[feat].values]\n",
    "#     valid[feat] = [diz_map_train[i] for i in valid[feat].values]\n",
    "#     test[feat] = [diz_map_train[i] for i in test[feat].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3}}\n",
      "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3}, 'EDUCATION': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, '4.0': 5, '5.0': 6, '6.0': 7, 'nan': 8}}\n",
      "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3}, 'EDUCATION': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, '4.0': 5, '5.0': 6, '6.0': 7, 'nan': 8}, 'MARRIAGE': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, 'nan': 5}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "      <th>sep_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20024.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29995</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22676.0</td>\n",
       "      <td>14647.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29996</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29997</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82607.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29998</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>8998.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29999</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>85900.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>52964.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0        20000.0    2          3         2  24.0    2.0    2.0   -1.0   -1.0   \n",
       "1       120000.0    2          8         3  26.0   -1.0    2.0    0.0    NaN   \n",
       "2        90000.0    2          3         3   NaN    0.0    0.0    0.0    0.0   \n",
       "3        50000.0    2          3         2  37.0    0.0    0.0    0.0    0.0   \n",
       "4        50000.0    1          8         5  37.0    0.0    0.0    0.0    0.0   \n",
       "...          ...  ...        ...       ...   ...    ...    ...    ...    ...   \n",
       "29995    50000.0    1          3         2  44.0    1.0    2.0    2.0    2.0   \n",
       "29996   240000.0    1          2         3  30.0   -2.0   -2.0   -2.0   -2.0   \n",
       "29997    80000.0    1          8         5  34.0    2.0    2.0    NaN    2.0   \n",
       "29998   150000.0    3          4         3  43.0    NaN   -1.0    NaN   -1.0   \n",
       "29999    80000.0    1          4         5  41.0    1.0   -1.0    NaN    NaN   \n",
       "\n",
       "       PAY_5  ...  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0       -2.0  ...        0.0        NaN       0.0     689.0       0.0   \n",
       "1        0.0  ...     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2        0.0  ...    14948.0    15549.0    1518.0    1500.0       NaN   \n",
       "3        0.0  ...    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4        0.0  ...        NaN    20024.0    2500.0    1815.0     657.0   \n",
       "...      ...  ...        ...        ...       ...       ...       ...   \n",
       "29995    0.0  ...    22676.0    14647.0    2300.0       NaN       0.0   \n",
       "29996   -2.0  ...        0.0        0.0       NaN       0.0       0.0   \n",
       "29997    2.0  ...    82607.0        NaN       NaN    3500.0       0.0   \n",
       "29998    NaN  ...     5190.0        0.0    1837.0    3526.0    8998.0   \n",
       "29999    0.0  ...        NaN    48944.0   85900.0    3409.0    1178.0   \n",
       "\n",
       "       PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  sep_idx  \n",
       "0           0.0       NaN       0.0                         1.0        1  \n",
       "1           NaN       0.0    2000.0                         1.0        1  \n",
       "2        1000.0    1000.0       NaN                         0.0        1  \n",
       "3        1100.0       NaN    1000.0                         0.0        1  \n",
       "4        1000.0       NaN     800.0                         0.0        1  \n",
       "...         ...       ...       ...                         ...      ...  \n",
       "29995     517.0     503.0     585.0                         0.0        0  \n",
       "29996       NaN       0.0       0.0                         0.0        0  \n",
       "29997    7000.0       0.0    4000.0                         1.0        0  \n",
       "29998     129.0       0.0       0.0                         0.0        0  \n",
       "29999    1926.0   52964.0    1804.0                         1.0        0  \n",
       "\n",
       "[30000 rows x 25 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train\n",
    "category_info  = {}\n",
    "for feat in fac_var:\n",
    "    findIDX = [idx for idx, i in enumerate(in_var) if i == feat][0]\n",
    "    lbe = LabelEncoder()\n",
    "    lbe.fit(data[feat].values)\n",
    "    diz_map_train = dict(zip(lbe.classes_, lbe.transform(lbe.classes_) + 1))\n",
    "    category_info[feat] = diz_map_train\n",
    "    print(category_info)\n",
    "train.replace(category_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3},\n",
       " 'EDUCATION': {'0.0': 1,\n",
       "  '1.0': 2,\n",
       "  '2.0': 3,\n",
       "  '3.0': 4,\n",
       "  '4.0': 5,\n",
       "  '5.0': 6,\n",
       "  '6.0': 7,\n",
       "  'nan': 8},\n",
       " 'MARRIAGE': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, 'nan': 5}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(category_info[\"SEX\"].keys())).difference(list(category_info[\"SEX\"].keys())) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1.0': 1, '2.0': 2, 'nan': 3}\n",
      "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3}}\n",
      "{'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, '4.0': 5, '5.0': 6, '6.0': 7, 'nan': 8}\n",
      "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3}, 'EDUCATION': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, '4.0': 5, '5.0': 6, '6.0': 7, 'nan': 8}}\n",
      "{'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, 'nan': 5}\n",
      "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3}, 'EDUCATION': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, '4.0': 5, '5.0': 6, '6.0': 7, 'nan': 8}, 'MARRIAGE': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, 'nan': 5}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "      <th>sep_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.136701</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.392377</td>\n",
       "      <td>2.017191e+00</td>\n",
       "      <td>1.984723</td>\n",
       "      <td>-7.770938e-01</td>\n",
       "      <td>-0.747120</td>\n",
       "      <td>-1.717958e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.405731e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.744710e-01</td>\n",
       "      <td>-0.283396</td>\n",
       "      <td>-0.355955</td>\n",
       "      <td>-3.489423e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.248907e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.365974</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.149702</td>\n",
       "      <td>-9.829589e-01</td>\n",
       "      <td>1.984723</td>\n",
       "      <td>1.544774e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.619441e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.772653e-01</td>\n",
       "      <td>-0.667745</td>\n",
       "      <td>-3.744710e-01</td>\n",
       "      <td>-0.266199</td>\n",
       "      <td>-0.286629</td>\n",
       "      <td>6.565034e-17</td>\n",
       "      <td>-0.355944</td>\n",
       "      <td>-2.009214e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.597192</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709094e-02</td>\n",
       "      <td>0.117591</td>\n",
       "      <td>1.544774e-01</td>\n",
       "      <td>0.205845</td>\n",
       "      <td>2.619441e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.666729e-01</td>\n",
       "      <td>-0.437237</td>\n",
       "      <td>-2.745985e-01</td>\n",
       "      <td>-0.238551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.767590e-01</td>\n",
       "      <td>-0.281265</td>\n",
       "      <td>-5.637471e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.905483</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.185013</td>\n",
       "      <td>1.709094e-02</td>\n",
       "      <td>0.117591</td>\n",
       "      <td>1.544774e-01</td>\n",
       "      <td>0.205845</td>\n",
       "      <td>2.619441e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.099418e-01</td>\n",
       "      <td>-0.174652</td>\n",
       "      <td>-2.428867e-01</td>\n",
       "      <td>-0.209853</td>\n",
       "      <td>-0.272763</td>\n",
       "      <td>-2.695407e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.629060e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.905483</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.185013</td>\n",
       "      <td>1.709094e-02</td>\n",
       "      <td>0.117591</td>\n",
       "      <td>1.544774e-01</td>\n",
       "      <td>0.205845</td>\n",
       "      <td>2.619441e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.333213e-16</td>\n",
       "      <td>-0.353292</td>\n",
       "      <td>-2.099906e-01</td>\n",
       "      <td>-0.221133</td>\n",
       "      <td>-0.310407</td>\n",
       "      <td>-2.767590e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.753029e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29995</td>\n",
       "      <td>-0.905483</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.034377</td>\n",
       "      <td>1.017141e+00</td>\n",
       "      <td>1.984723</td>\n",
       "      <td>2.017620e+00</td>\n",
       "      <td>2.111775</td>\n",
       "      <td>2.619441e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.250686e-01</td>\n",
       "      <td>-0.454158</td>\n",
       "      <td>-2.231490e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.355955</td>\n",
       "      <td>-3.116236e-01</td>\n",
       "      <td>-0.318380</td>\n",
       "      <td>-2.886296e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29996</td>\n",
       "      <td>0.558898</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.664351</td>\n",
       "      <td>-1.983009e+00</td>\n",
       "      <td>-1.749541</td>\n",
       "      <td>-1.708665e+00</td>\n",
       "      <td>-1.700085</td>\n",
       "      <td>-1.717958e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.405731e-01</td>\n",
       "      <td>-0.728917</td>\n",
       "      <td>5.983762e-17</td>\n",
       "      <td>-0.321495</td>\n",
       "      <td>-0.355955</td>\n",
       "      <td>6.565034e-17</td>\n",
       "      <td>-0.355944</td>\n",
       "      <td>-3.248907e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29997</td>\n",
       "      <td>-0.674265</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.179000</td>\n",
       "      <td>2.017191e+00</td>\n",
       "      <td>1.984723</td>\n",
       "      <td>2.585629e-17</td>\n",
       "      <td>2.111775</td>\n",
       "      <td>2.241846e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.730792e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.983762e-17</td>\n",
       "      <td>-0.127960</td>\n",
       "      <td>-0.355955</td>\n",
       "      <td>1.563409e-01</td>\n",
       "      <td>-0.355944</td>\n",
       "      <td>-7.695207e-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29998</td>\n",
       "      <td>-0.134756</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.913039</td>\n",
       "      <td>-1.040886e-17</td>\n",
       "      <td>-0.815975</td>\n",
       "      <td>2.585629e-17</td>\n",
       "      <td>-0.747120</td>\n",
       "      <td>-5.495333e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.454740e-01</td>\n",
       "      <td>-0.728917</td>\n",
       "      <td>-2.536108e-01</td>\n",
       "      <td>-0.126522</td>\n",
       "      <td>0.267843</td>\n",
       "      <td>-3.396307e-01</td>\n",
       "      <td>-0.355944</td>\n",
       "      <td>-3.248907e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29999</td>\n",
       "      <td>-0.674265</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.670364</td>\n",
       "      <td>1.017141e+00</td>\n",
       "      <td>-0.815975</td>\n",
       "      <td>2.585629e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.619441e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.333213e-16</td>\n",
       "      <td>0.189211</td>\n",
       "      <td>5.277075e+00</td>\n",
       "      <td>-0.132991</td>\n",
       "      <td>-0.274288</td>\n",
       "      <td>-2.099173e-01</td>\n",
       "      <td>3.599350</td>\n",
       "      <td>-2.130704e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE       AGE         PAY_0     PAY_2  \\\n",
       "0      -1.136701    2          3         2 -1.392377  2.017191e+00  1.984723   \n",
       "1      -0.365974    2          8         3 -1.149702 -9.829589e-01  1.984723   \n",
       "2      -0.597192    2          3         3  0.000000  1.709094e-02  0.117591   \n",
       "3      -0.905483    2          3         2  0.185013  1.709094e-02  0.117591   \n",
       "4      -0.905483    1          8         5  0.185013  1.709094e-02  0.117591   \n",
       "...          ...  ...        ...       ...       ...           ...       ...   \n",
       "29995  -0.905483    1          3         2  1.034377  1.017141e+00  1.984723   \n",
       "29996   0.558898    1          2         3 -0.664351 -1.983009e+00 -1.749541   \n",
       "29997  -0.674265    1          8         5 -0.179000  2.017191e+00  1.984723   \n",
       "29998  -0.134756    3          4         3  0.913039 -1.040886e-17 -0.815975   \n",
       "29999  -0.674265    1          4         5  0.670364  1.017141e+00 -0.815975   \n",
       "\n",
       "              PAY_3     PAY_4         PAY_5  ...     BILL_AMT5  BILL_AMT6  \\\n",
       "0     -7.770938e-01 -0.747120 -1.717958e+00  ... -7.405731e-01   0.000000   \n",
       "1      1.544774e-01  0.000000  2.619441e-01  ... -6.772653e-01  -0.667745   \n",
       "2      1.544774e-01  0.205845  2.619441e-01  ... -4.666729e-01  -0.437237   \n",
       "3      1.544774e-01  0.205845  2.619441e-01  ... -2.099418e-01  -0.174652   \n",
       "4      1.544774e-01  0.205845  2.619441e-01  ... -1.333213e-16  -0.353292   \n",
       "...             ...       ...           ...  ...           ...        ...   \n",
       "29995  2.017620e+00  2.111775  2.619441e-01  ... -3.250686e-01  -0.454158   \n",
       "29996 -1.708665e+00 -1.700085 -1.717958e+00  ... -7.405731e-01  -0.728917   \n",
       "29997  2.585629e-17  2.111775  2.241846e+00  ...  7.730792e-01   0.000000   \n",
       "29998  2.585629e-17 -0.747120 -5.495333e-17  ... -6.454740e-01  -0.728917   \n",
       "29999  2.585629e-17  0.000000  2.619441e-01  ... -1.333213e-16   0.189211   \n",
       "\n",
       "           PAY_AMT1  PAY_AMT2  PAY_AMT3      PAY_AMT4  PAY_AMT5      PAY_AMT6  \\\n",
       "0     -3.744710e-01 -0.283396 -0.355955 -3.489423e-01  0.000000 -3.248907e-01   \n",
       "1     -3.744710e-01 -0.266199 -0.286629  6.565034e-17 -0.355944 -2.009214e-01   \n",
       "2     -2.745985e-01 -0.238551  0.000000 -2.767590e-01 -0.281265 -5.637471e-17   \n",
       "3     -2.428867e-01 -0.209853 -0.272763 -2.695407e-01  0.000000 -2.629060e-01   \n",
       "4     -2.099906e-01 -0.221133 -0.310407 -2.767590e-01  0.000000 -2.753029e-01   \n",
       "...             ...       ...       ...           ...       ...           ...   \n",
       "29995 -2.231490e-01  0.000000 -0.355955 -3.116236e-01 -0.318380 -2.886296e-01   \n",
       "29996  5.983762e-17 -0.321495 -0.355955  6.565034e-17 -0.355944 -3.248907e-01   \n",
       "29997  5.983762e-17 -0.127960 -0.355955  1.563409e-01 -0.355944 -7.695207e-02   \n",
       "29998 -2.536108e-01 -0.126522  0.267843 -3.396307e-01 -0.355944 -3.248907e-01   \n",
       "29999  5.277075e+00 -0.132991 -0.274288 -2.099173e-01  3.599350 -2.130704e-01   \n",
       "\n",
       "       default payment next month  sep_idx  \n",
       "0                             1.0        1  \n",
       "1                             1.0        1  \n",
       "2                             0.0        1  \n",
       "3                             0.0        1  \n",
       "4                             0.0        1  \n",
       "...                           ...      ...  \n",
       "29995                         0.0        0  \n",
       "29996                         0.0        0  \n",
       "29997                         1.0        0  \n",
       "29998                         0.0        0  \n",
       "29999                         1.0        0  \n",
       "\n",
       "[30000 rows x 25 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train\n",
    "category_info  = {}\n",
    "for feat in fac_var:\n",
    "    findIDX = [idx for idx, i in enumerate(in_var) if i == feat][0]\n",
    "    lbe = LabelEncoder()\n",
    "    lbe.fit(data[feat].values)\n",
    "    diz_map_train = dict(zip(lbe.classes_, lbe.transform(lbe.classes_) + 1))\n",
    "    print(diz_map_train)\n",
    "    category_info[feat] = diz_map_train\n",
    "#     print(category_info)\n",
    "# train.replace(category_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(np.array([\"4.0\",\"5.0\",\"2.0\"])).difference((list(category_info[\"SEX\"].keys()))) :\n",
    "    category_info[\"SEX\"].update({i : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEX': {'1.0': 1, '2.0': 2, 'nan': 3, '4.0': 0, '5.0': 0},\n",
       " 'EDUCATION': {'0.0': 1,\n",
       "  '1.0': 2,\n",
       "  '2.0': 3,\n",
       "  '3.0': 4,\n",
       "  '4.0': 5,\n",
       "  '5.0': 6,\n",
       "  '6.0': 7,\n",
       "  'nan': 8},\n",
       " 'MARRIAGE': {'0.0': 1, '1.0': 2, '2.0': 3, '3.0': 4, 'nan': 5}}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
